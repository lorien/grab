.. _spider_cache:

====================================
Система кэширования сетевых запросов
====================================

В целях ускорения тестирования паука в процессе разработки, а также ускорения повторного парсинга данных, была разработана система кэширования. В данный момент есть ограничение - только GET запросы могут быть закешированными. Важно понимать что кэш в Spider это не полноценный http-прокси-сервер это лишь средство для отладки. Хотя стоит заметить, что даже в таком примитивной реализации система кэширования в большинстве случаев позволяет успешно использовать закэшированные данные для повторного парсинга в случае изменения логики обработки данных.

Бэкенды системы кэширования
---------------------------

Кэш в Spider разработан в виде отдельного слоя для того, чтобы можно было подключать различные базы данных. В данный момент доступна только одна реализация кэша - хранение данных в mongodb.

Использование кэша
-----------------

Для того, чтобы паук мог искать запрашиваемые документы в кэше и сохранять в кэш полученные данные, нужно вызывать метод `setup_cache` до начала работы паука::

    bot = ExampleSpider()
    bot.setup_cache(database='some-database')
    bot.run()

Вышенаписанный код активирует кэш, документы будут искаться и сохраняться в базе данных mongodb с именем 'some-database'. Имя коллекции с документами: "cache".

Есть несколько настроек для регулирования работы кэша:

:backend: бэкенд кэша, сейчас ничего кроме "mongo" не работает
:database: имя mongodb базы данных
:use_compression: использование gzip для сжатия данных перед помещением их в кэш.

Сжатие кэшируемых данных
------------------------

По умолчанию сжатие включено. Сжатие позволяет на порядок уменьшить размер места в базе данных, необходимого для хранения закешированных документов. Сжатие снижает скорость работы паука, но не намного.
